{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS591 HW2 by Ziran Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_shakespeare():\n",
    "    tuples = []\n",
    "    \n",
    "    with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        for row in csv_reader:\n",
    "            play_name = row[1]\n",
    "            line = row[5]\n",
    "            line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "            line_tokens = [token.lower() for token in line_tokens]\n",
    "\n",
    "            tuples.append((play_name, line_tokens))\n",
    "    \n",
    "    with open('vocab.txt') as f:\n",
    "        vocab =  [line.strip() for line in f]\n",
    "    with open('play_names.txt') as f:\n",
    "        document_names =  [line.strip() for line in f]\n",
    "    \n",
    "    return tuples, document_names, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_vector(matrix, row_id):\n",
    "    return matrix[row_id, :]\n",
    "\n",
    "def get_column_vector(matrix, col_id):\n",
    "    return matrix[:, col_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_document_matrix(line_tuples, document_names, vocab):\n",
    "    vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "    docname_to_id = dict(zip(document_names, range(0, len(document_names))))\n",
    "    \n",
    "    # num of vocabs\n",
    "    a = len(vocab_to_id)\n",
    "    # num of documents\n",
    "    b = len(docname_to_id)\n",
    "    # initialize result matrix\n",
    "    result = np.zeros((a,b))\n",
    "      \n",
    "    for i in line_tuples: \n",
    "        # find each doc index\n",
    "        doc = docname_to_id[i[0]]\n",
    "        for j in i[1]:\n",
    "            # find vocab index \n",
    "            word = vocab_to_id[j]\n",
    "            result[word,doc] +=  1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_context_matrix(line_tuples, vocab, context_window_size=1):\n",
    "    vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "    \n",
    "    # num of vocabs\n",
    "    n = len(vocab_to_id)\n",
    "    # initialize result matrix\n",
    "    result = np.zeros((n,n))\n",
    "\n",
    "    for i in line_tuples: \n",
    "        words_line = i[1]  \n",
    "        for j, word in enumerate(words_line): \n",
    "            # setting upper and lowerbound of range for search words\n",
    "            upper_bound = min(j + context_window_size + 1, len(words_line))\n",
    "            lower_bound = max(0, j - context_window_size)\n",
    "            \n",
    "            # adding counts into result matrix\n",
    "            for k in range(lower_bound, upper_bound):\n",
    "                row_word = vocab_to_id[word]\n",
    "                col_word = vocab_to_id[words_line[k]] \n",
    "                result[row_word,col_word] += 1\n",
    "  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighting Terms\n",
    "### PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PPMI_matrix(term_context_matrix):\n",
    "    total_count = np.sum(term_context_matrix)\n",
    "      \n",
    "    # compute p_ij\n",
    "    p_ij = (term_context_matrix ) / total_count\n",
    "    \n",
    "    # compute p_i\n",
    "    p_i = np.sum(p_ij, axis=1)[:,None]  \n",
    "    # compute p_j\n",
    "    p_j = np.sum(p_ij, axis=0)[None,:]  \n",
    "  \n",
    "    temp1 = np.ones(term_context_matrix.shape)\n",
    "    temp2 = temp1 / p_i\n",
    "    temp3 = temp2 / p_j\n",
    "  \n",
    "    # take log\n",
    "    result = np.log2(p_ij * temp3)\n",
    "    # change negative to zero\n",
    "    result = np.maximum(result, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Prof. Wijaya on Piazza\n",
    "# Use the simplest definition of TFIDF\n",
    "# f = count(t, d) --> term frequency \n",
    "# idf = log (N / number_of_docs_with_the_term_t)  --> inverse document frequency, log here is natural log\n",
    "# tfidf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_matrix(term_document_matrix):\n",
    "    word_num, docs_num = term_document_matrix.shape\n",
    "    df = np.sum( term_document_matrix > 0, axis=1)\n",
    "    idf = np.log(docs_num / df)\n",
    "    tfidf = np.multiply(term_document_matrix, idf.reshape(word_num,1))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(vector1, vector2):\n",
    "    # by formula\n",
    "    num = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    return num/(norm1*norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(vector1, vector2):\n",
    "    # by formula\n",
    "    num = np.sum(np.minimum(vector1,vector2))\n",
    "    den = np.sum(np.maximum(vector1,vector2))\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_similarity(vector1, vector2):\n",
    "    # by formula\n",
    "    num = 2.0 * np.sum(np.minimum(vector1, vector2))\n",
    "    den = np.sum(vector1+vector2)\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_plays(target_play_index, term_document_matrix, similarity_fn):\n",
    "    # num of plays\n",
    "    n = term_document_matrix.shape[1]\n",
    "    # initialize simliarities list\n",
    "    sim_l = np.zeros(n)\n",
    "    \n",
    "    # vector of target play\n",
    "    target_vector = get_column_vector(term_document_matrix, target_play_index)\n",
    "    \n",
    "    # find similarities with each other play\n",
    "    for i in range(n):\n",
    "        # vector of each other play\n",
    "        compared_vector = get_column_vector(term_document_matrix, i)\n",
    "        sim_l[i] = similarity_fn(target_vector, compared_vector)\n",
    "    \n",
    "    # sorting and ranking\n",
    "    result = np.argsort(-sim_l)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_words(target_word_index, matrix, similarity_fn):\n",
    "    # num of wrods\n",
    "    n = matrix.shape[1]\n",
    "    # initialize simliarities list\n",
    "    sim_l = np.zeros(n)\n",
    "    \n",
    "    # vector of target words\n",
    "    target_vector = get_row_vector(matrix, target_word_index)\n",
    "    \n",
    "    # find similarities with each other words\n",
    "    for i in range(n):\n",
    "        # vector of each other words\n",
    "        compared_vector = get_row_vector(matrix, i)\n",
    "        sim_l[i] = similarity_fn(target_vector, compared_vector)\n",
    "    \n",
    "    # sorting and ranking\n",
    "    result = np.argsort(-sim_l)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term document matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing term document matrix...')\n",
    "td_matrix = create_term_document_matrix(tuples, document_names, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 5., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing tf-idf matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing tf-idf matrix...')\n",
    "tf_idf_matrix = create_tf_idf_matrix(td_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 2.19722458, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 3.4657359 , 0.        , ..., 0.69314718, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.28093385, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term context matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing term context matrix...')\n",
    "tc_matrix = create_term_context_matrix(tuples, vocab, context_window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., 10.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 47., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., 23.]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PPMI matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing PPMI matrix...')\n",
    "PPMI_matrix = create_PPMI_matrix(tc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.58027329,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , 14.35702238,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , 12.28919786, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., 17.1063421 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        17.1063421 ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , 12.7373916 ]])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar plays to \"King John\" using compute_cosine_similarity are:\n",
      "1: King John\n",
      "2: Henry VI Part 1\n",
      "3: Richard II\n",
      "4: Henry VI Part 2\n",
      "5: Henry V\n",
      "6: Richard III\n",
      "7: Henry IV\n",
      "8: Hamlet\n",
      "9: macbeth\n",
      "10: Cymbeline\n",
      "\n",
      "The 10 most similar plays to \"King John\" using compute_jaccard_similarity are:\n",
      "1: King John\n",
      "2: Richard II\n",
      "3: Henry VI Part 1\n",
      "4: Titus Andronicus\n",
      "5: Henry IV\n",
      "6: Henry VI Part 2\n",
      "7: Henry VI Part 3\n",
      "8: Pericles\n",
      "9: Romeo and Juliet\n",
      "10: Merchant of Venice\n",
      "\n",
      "The 10 most similar plays to \"King John\" using compute_dice_similarity are:\n",
      "1: King John\n",
      "2: Richard II\n",
      "3: Henry VI Part 1\n",
      "4: Titus Andronicus\n",
      "5: Henry IV\n",
      "6: Henry VI Part 2\n",
      "7: Henry VI Part 3\n",
      "8: Pericles\n",
      "9: Romeo and Juliet\n",
      "10: Merchant of Venice\n"
     ]
    }
   ],
   "source": [
    "random_idx = random.randint(0, len(document_names)-1)\n",
    "similarity_fns = [compute_cosine_similarity, compute_jaccard_similarity, compute_dice_similarity]\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar plays to \"%s\" using %s are:' % (document_names[random_idx], sim_fn.__qualname__))\n",
    "    ranks = rank_plays(random_idx, td_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "        doc_id = ranks[idx]\n",
    "        print('%d: %s' % (idx+1, document_names[doc_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on term-document frequency matrix are:\n",
      "1: scaring\n",
      "2: dreamt\n",
      "3: umpire\n",
      "4: lovers\n",
      "5: pipes\n",
      "6: mood\n",
      "7: nobleman\n",
      "8: success\n",
      "9: fenton\n",
      "10: couplement\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on term-document frequency matrix are:\n",
      "1: lovers\n",
      "2: dreamt\n",
      "3: nobleman\n",
      "4: scaring\n",
      "5: umpire\n",
      "6: pipes\n",
      "7: mood\n",
      "8: success\n",
      "9: enticements\n",
      "10: fenton\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on term-document frequency matrix are:\n",
      "1: lovers\n",
      "2: dreamt\n",
      "3: nobleman\n",
      "4: scaring\n",
      "5: umpire\n",
      "6: pipes\n",
      "7: mood\n",
      "8: success\n",
      "9: enticements\n",
      "10: fenton\n"
     ]
    }
   ],
   "source": [
    "word = 'juliet'\n",
    "vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on term-document frequency matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], td_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "        word_id = ranks[idx]\n",
    "        print('%d: %s' % (idx+1, vocab[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on term-context frequency matrix are:\n",
      "1: juliet\n",
      "2: and\n",
      "3: drinkings\n",
      "4: pined\n",
      "5: scamble\n",
      "6: metheglins\n",
      "7: groaning\n",
      "8: cymbals\n",
      "9: bleated\n",
      "10: grunt\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on term-context frequency matrix are:\n",
      "1: juliet\n",
      "2: silvia\n",
      "3: nurse\n",
      "4: orlando\n",
      "5: proteus\n",
      "6: othello\n",
      "7: demetrius\n",
      "8: leonato\n",
      "9: hamlet\n",
      "10: marcus\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on term-context frequency matrix are:\n",
      "1: juliet\n",
      "2: silvia\n",
      "3: nurse\n",
      "4: orlando\n",
      "5: proteus\n",
      "6: othello\n",
      "7: demetrius\n",
      "8: leonato\n",
      "9: hamlet\n",
      "10: marcus\n"
     ]
    }
   ],
   "source": [
    "word = 'juliet'\n",
    "vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on term-context frequency matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], tc_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "        word_id = ranks[idx]\n",
    "        print('%d: %s' % (idx+1, vocab[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on PPMI matrix are:\n",
      "1: scaring\n",
      "2: dreamt\n",
      "3: umpire\n",
      "4: lovers\n",
      "5: pipes\n",
      "6: mood\n",
      "7: nobleman\n",
      "8: success\n",
      "9: fenton\n",
      "10: couplement\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on PPMI matrix are:\n",
      "1: lovers\n",
      "2: scaring\n",
      "3: dreamt\n",
      "4: umpire\n",
      "5: nobleman\n",
      "6: pipes\n",
      "7: mood\n",
      "8: success\n",
      "9: enticements\n",
      "10: fenton\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on PPMI matrix are:\n",
      "1: lovers\n",
      "2: scaring\n",
      "3: dreamt\n",
      "4: umpire\n",
      "5: nobleman\n",
      "6: pipes\n",
      "7: mood\n",
      "8: success\n",
      "9: enticements\n",
      "10: fenton\n"
     ]
    }
   ],
   "source": [
    "word = 'juliet'\n",
    "vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on PPMI matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], tf_idf_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "        word_id = ranks[idx]\n",
    "        print('%d: %s' % (idx+1, vocab[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on PPMI matrix are:\n",
      "1: juliet\n",
      "2: pined\n",
      "3: waken\n",
      "4: capulet\n",
      "5: tybalt\n",
      "6: muffled\n",
      "7: fares\n",
      "8: provost\n",
      "9: wills\n",
      "10: county\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on PPMI matrix are:\n",
      "1: juliet\n",
      "2: tybalt\n",
      "3: capulet\n",
      "4: silvia\n",
      "5: lucio\n",
      "6: nurse\n",
      "7: romeo\n",
      "8: montague\n",
      "9: leonato\n",
      "10: provost\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on PPMI matrix are:\n",
      "1: juliet\n",
      "2: tybalt\n",
      "3: capulet\n",
      "4: silvia\n",
      "5: lucio\n",
      "6: nurse\n",
      "7: romeo\n",
      "8: montague\n",
      "9: leonato\n",
      "10: provost\n"
     ]
    }
   ],
   "source": [
    "word = 'juliet'\n",
    "vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on PPMI matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], PPMI_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "        word_id = ranks[idx]\n",
    "        print('%d: %s' % (idx+1, vocab[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
